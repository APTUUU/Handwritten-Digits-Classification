{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9194640e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:purple; font-family:Helvetica Neue\">HandwrittenDigits Classification</h1>\n",
    "<hr>\n",
    "<h7>SourceðŸ¤–:<a href=\"https://github.com/APTUUU/Handwritten-Digits-Classification\">Handwritten Digits Classifier</a></h7>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593fbf0",
   "metadata": {},
   "source": [
    "# Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d803507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed(88)\n",
    "set_seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e5e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3be25",
   "metadata": {},
   "source": [
    "# Constants\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785a3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "\n",
    "# Nr. of Digits\n",
    "NR_CLASSES = 10\n",
    "\n",
    "# Validation Dataset\n",
    "VALIDATION_SIZE = 10_000\n",
    "\n",
    "# Nr. of Inputs\n",
    "TOTAL_INPUTS = 28 * 28 * 1\n",
    "\n",
    "# Logging Paths\n",
    "LOGGING_PATH = 'tensorboard_mnist_digit_logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8d2db",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89f1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0716fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c19489",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2028e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8204b8b",
   "metadata": {},
   "source": [
    "# Exploring Data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377accf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10f8571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c415c",
   "metadata": {},
   "source": [
    "# Pre-Processing Data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d9c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255, x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c8e48",
   "metadata": {},
   "source": [
    "### Convert Target-values to One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcd381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(NR_CLASSES)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ae10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f9baf",
   "metadata": {},
   "source": [
    "### Create Validation Datset from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a0cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_train[:VALIDATION_SIZE]\n",
    "x_val = x_train[:VALIDATION_SIZE]\n",
    "y_train = y_train[VALIDATION_SIZE:]\n",
    "x_train = x_train[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2472ea4",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Graph\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e31c0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba172ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, TOTAL_INPUTS], name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f6a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "Y = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, NR_CLASSES], name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ada7f",
   "metadata": {},
   "source": [
    "# Neural Network Architecture\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b0965",
   "metadata": {},
   "source": [
    "#### Hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed03de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 18\n",
    "learning_rate = 1e-3   #0.001\n",
    "\n",
    "nr_hidden_layer1 = 512\n",
    "nr_hidden_layer2 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ea9b4",
   "metadata": {},
   "source": [
    "#### First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0831bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Hidden_Layer_1'):\n",
    "    \n",
    "    # weights\n",
    "    initial_weight1 = tf.random.truncated_normal(shape=[TOTAL_INPUTS, nr_hidden_layer1], stddev=0.1, seed=42)\n",
    "    weight1 = tf.Variable(initial_weight1, name='weight_1')\n",
    "\n",
    "    # bias\n",
    "    initial_bias1 = tf.constant(value=0.0, shape=[nr_hidden_layer1])  # shape = (nr_hidden_layer2,)\n",
    "    bias1 = tf.Variable(initial_bias1, name='bias_1')\n",
    "\n",
    "    layer1_in = tf.matmul(X, weight1) + bias1\n",
    "    layer1_out = tf.nn.relu(features=layer1_in)\n",
    "    \n",
    "    tf.compat.v1.summary.histogram('weights', weight1)\n",
    "    tf.compat.v1.summary.histogram('bias', bias1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742d2c9",
   "metadata": {},
   "source": [
    "#### Second Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff8f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Hidden_Layer_2'):    \n",
    "    \n",
    "    # weights\n",
    "    initial_weight2 = tf.random.truncated_normal(shape=[nr_hidden_layer1, nr_hidden_layer2], stddev=0.1, seed=42)\n",
    "    weight2 = tf.Variable(initial_weight2, name='weight_2')\n",
    "\n",
    "    # bias\n",
    "    initial_bias2 = tf.constant(value=0.0, shape= [nr_hidden_layer2])   # shape = (nr_hidden_layer2,)\n",
    "    bias2 = tf.Variable(initial_bias2, name='bias_2')\n",
    "\n",
    "    layer2_in = tf.matmul(layer1_out, weight2) + bias2\n",
    "    layer2_out = tf.nn.relu(layer2_in)\n",
    "    \n",
    "    tf.compat.v1.summary.histogram('weights', weight2)\n",
    "    tf.compat.v1.summary.histogram('bias', bias2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f5c9d",
   "metadata": {},
   "source": [
    "#### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e68d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Output_Layer'):    \n",
    "    \n",
    "    # weights\n",
    "    initial_weight3 = tf.random.truncated_normal(shape=[nr_hidden_layer2, NR_CLASSES], stddev=0.1, seed=42)\n",
    "    weight3 = tf.Variable(initial_weight3, name='weight_3')\n",
    "\n",
    "    # bias\n",
    "    initial_bias3 = tf.constant(value=0.0, shape= [NR_CLASSES])   \n",
    "    bias3 = tf.Variable(initial_bias3, name='bias_3')\n",
    "\n",
    "    layer3_in = tf.matmul(layer2_out, weight3) + bias3\n",
    "    output = tf.nn.softmax(layer3_in)\n",
    "    \n",
    "    tf.compat.v1.summary.histogram('weights', weight3)\n",
    "    tf.compat.v1.summary.histogram('bias', bias3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469e090",
   "metadata": {},
   "source": [
    "#### DropOut Layer (Optional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ff47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO Layer Setup\n",
    "# dropout_layer = tf.compat.v1.nn.dropout(layer1_out, keep_prob=0.8, name='DropOut_Layer')\n",
    "\n",
    "# # Changes to Second Layer\n",
    "# layer2_in = tf.matmul(dropout_out, weight2) + bias2\n",
    "# layer2_out = tf.nn.relu(layer2_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e2657",
   "metadata": {},
   "source": [
    "# Tensorboard Setup\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc84c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder for Tensorboard\n",
    "model_name = f'{nr_hidden_layer1}-{nr_hidden_layer2} LR{learning_rate} E{nr_epochs}'\n",
    "folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "try: \n",
    "    os.makedirs(directory)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df7d22",
   "metadata": {},
   "source": [
    "#### Tenseroard link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8d1c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=C:\\Users\\momoh\\DataScienceProjects\\ML\\HANDWRITTEN_DIGITS_CLASSIFICATION\\tensorboard_mnist_digit_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52fd8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=C:\\Users\\momoh\\Desktop\\Project\\HANDWRITTEN_DIGITS_CLASSIFICATION\\tensorboard_mnist_digit_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05354fe5",
   "metadata": {},
   "source": [
    "# Loss, Optimisation & Metrics\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f4d42",
   "metadata": {},
   "source": [
    "####  Defining Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbb39c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Loss_Calculation'):    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d43083",
   "metadata": {},
   "source": [
    "####  Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cefcf980",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Optimizer'):\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_step = optimizer.minimize(loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48df0b3",
   "metadata": {},
   "source": [
    "#### Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e405025",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Accuracy_Calculation'):\n",
    "    model_prediction = tf.argmax(Y, axis=1, name='Prediction')\n",
    "    correct_pred = tf.equal(model_prediction, tf.argmax(output, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff44bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Performance'):    \n",
    "    tf.compat.v1.summary.scalar('accuracy', accuracy)\n",
    "    tf.compat.v1.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a0f7f",
   "metadata": {},
   "source": [
    "#### Check Input Images in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc8c5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.name_scope('Show_Image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    tf.compat.v1.summary.image('Image_Input', x_image, max_outputs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0ae3e",
   "metadata": {},
   "source": [
    "# Run Session\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2898b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98911c2e",
   "metadata": {},
   "source": [
    "#### Setup Filewriter and Merge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6e50352",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.compat.v1.summary.merge_all()\n",
    "\n",
    "train_writer = tf.compat.v1.summary.FileWriter(directory + '/train')\n",
    "train_writer.add_graph(sess.graph)\n",
    "\n",
    "validation_writer = tf.compat.v1.summary.FileWriter(directory + '/validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d15e29",
   "metadata": {},
   "source": [
    "#### Initialize all Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7196e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d7042",
   "metadata": {},
   "source": [
    "# Batching Data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "577b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "716801e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = y_train.shape[0]\n",
    "nr_iterations = int(num_examples/size_of_batch)\n",
    "\n",
    "idx_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bb120d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global idx_epochs\n",
    "    \n",
    "    start = idx_epochs\n",
    "    idx_epochs += batch_size\n",
    "    \n",
    "    if idx_epochs > num_examples:\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        \n",
    "    end = idx_epochs\n",
    "    \n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcd6c0",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b452f3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t| Training Accuracy : [0.859]\n",
      "Epoch 1 \t| Training Accuracy : [0.85268]\n",
      "Epoch 2 \t| Training Accuracy : [0.8679]\n",
      "Epoch 3 \t| Training Accuracy : [0.8776]\n",
      "Epoch 4 \t| Training Accuracy : [0.8844]\n",
      "Epoch 5 \t| Training Accuracy : [0.89588]\n",
      "Epoch 6 \t| Training Accuracy : [0.98148]\n",
      "Epoch 7 \t| Training Accuracy : [0.98644]\n",
      "Epoch 8 \t| Training Accuracy : [0.98862]\n",
      "Epoch 9 \t| Training Accuracy : [0.98982]\n",
      "Epoch 10 \t| Training Accuracy : [0.99106]\n",
      "Epoch 11 \t| Training Accuracy : [0.99178]\n",
      "Epoch 12 \t| Training Accuracy : [0.9925]\n",
      "Epoch 13 \t| Training Accuracy : [0.99304]\n",
      "Epoch 14 \t| Training Accuracy : [0.9933]\n",
      "Epoch 15 \t| Training Accuracy : [0.99346]\n",
      "Epoch 16 \t| Training Accuracy : [0.9937]\n",
      "Epoch 17 \t| Training Accuracy : [0.994]\n",
      "Finished Training.\n",
      "Wall time: 12min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    # ============ Training ===============\n",
    "    \n",
    "    for i in range(nr_iterations):\n",
    "        \n",
    "        X_batch, Y_batch = next_batch(batch_size=size_of_batch, data=x_train, labels=y_train)\n",
    "        feed_dictionary = {X:X_batch, Y:Y_batch}\n",
    "        \n",
    "        # Training the Model\n",
    "        sess.run(fetches=train_step, feed_dict=feed_dictionary)\n",
    "        \n",
    "    # Training Accuracy \n",
    "    batch_accuracy = sess.run(fetches=[accuracy], feed_dict=feed_dictionary)\n",
    "    \n",
    "    # Training Summary\n",
    "    s = sess.run(fetches=merged_summary, feed_dict=feed_dictionary)\n",
    "    train_writer.add_summary(s, epoch)\n",
    "        \n",
    "    print(f'Epoch {epoch} \\t| Training Accuracy : {batch_accuracy}')\n",
    "    \n",
    "    # =========== Validation ================\n",
    "    \n",
    "    # Validation Summary\n",
    "    val_summary = sess.run(fetches=merged_summary, feed_dict={X:x_val, Y:y_val})\n",
    "    validation_writer.add_summary(val_summary, epoch)\n",
    "    \n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c75753",
   "metadata": {},
   "source": [
    "# Saving the Model\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "668e6e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\momoh\\AppData\\Local\\Temp\\ipykernel_10536\\917254497.py:5: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From C:\\Users\\momoh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    }
   ],
   "source": [
    "inputs = {'X': X}\n",
    "outputs = {'Accuracy_Calculation/Prediction': model_prediction}\n",
    "\n",
    "try:\n",
    "    tf.compat.v1.saved_model.simple_save(sess, f'SavedModel-{model_name}', inputs, outputs)\n",
    "except AssertionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc616",
   "metadata": {},
   "source": [
    "# Making a Prediction\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "105124aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('MNIST/test_img.png')\n",
    "bw = img.convert('L')\n",
    "img_array = np.invert(bw)\n",
    "test_img = np.ravel(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ca3ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0935b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95b35462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image prediction is [2]\n"
     ]
    }
   ],
   "source": [
    "print('Image prediction is {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f6fb6",
   "metadata": {},
   "source": [
    "# Test and Evaluation\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f745bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Prediction Accuracy is 97.64%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test, Y:y_test})\n",
    "print('Test Dataset Prediction Accuracy is {:.2%}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c7e7e",
   "metadata": {},
   "source": [
    "# Reset for the Next Run\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "693f0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Mouhamed Aziz Laabidi"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "title": "TF Handwritten Digits Classifier"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
